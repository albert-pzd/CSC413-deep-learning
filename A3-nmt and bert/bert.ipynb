{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff87ebfa21374d2e95eaba862684e79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ec75762dc7745a1b2669e458ea806e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_645d42b6fa0a49519325e6164373ac4c",
              "IPY_MODEL_45bd34b264f043b291fdf8d256c62a86"
            ]
          }
        },
        "9ec75762dc7745a1b2669e458ea806e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "645d42b6fa0a49519325e6164373ac4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14e6d658b30a4e87ae84e40ddad35850",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b887af5e0c94c379c5fdc936be2686e"
          }
        },
        "45bd34b264f043b291fdf8d256c62a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd911470db74449ca6c087f3d4117ca4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 910kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2c035b0c8934108a6df33f59c68d40e"
          }
        },
        "14e6d658b30a4e87ae84e40ddad35850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b887af5e0c94c379c5fdc936be2686e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd911470db74449ca6c087f3d4117ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2c035b0c8934108a6df33f59c68d40e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cdc593b8b8d4cc5b163770a9b5b84ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae2c68f5d4124b8894ad0f2ef862986c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9090201986146768b7cb7d3c3d60700",
              "IPY_MODEL_d10c39f0720543d3ab656eaeed97f9f1"
            ]
          }
        },
        "ae2c68f5d4124b8894ad0f2ef862986c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9090201986146768b7cb7d3c3d60700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aaa8120662b1443abbca5e02f82d4884",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8a7d4005bef445b8549c282bed0cde3"
          }
        },
        "d10c39f0720543d3ab656eaeed97f9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08668862d5f445238f886fae2f089689",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 12.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac52645f834f455086cee795a232c7d8"
          }
        },
        "aaa8120662b1443abbca5e02f82d4884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8a7d4005bef445b8549c282bed0cde3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08668862d5f445238f886fae2f089689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac52645f834f455086cee795a232c7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a58b5eb80e544fb98109faefca75b680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e587f3863134a9b86c4f57a65b377f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_411a06cd7a2d4f9f8f141cc217dfd394",
              "IPY_MODEL_052e678e5a8a4550b00f7cb67e7c44e0"
            ]
          }
        },
        "8e587f3863134a9b86c4f57a65b377f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "411a06cd7a2d4f9f8f141cc217dfd394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9952277b59e1417b822075883d4a1d7b",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6b6fa089a814862b594eb4633c65e1b"
          }
        },
        "052e678e5a8a4550b00f7cb67e7c44e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2909d7d5deea4916b3014c4ed2c09d61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:14&lt;00:00, 29.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c29cecbf01b403e8bc60b8a8cd5b3c8"
          }
        },
        "9952277b59e1417b822075883d4a1d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6b6fa089a814862b594eb4633c65e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2909d7d5deea4916b3014c4ed2c09d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c29cecbf01b403e8bc60b8a8cd5b3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej",
        "colab_type": "text"
      },
      "source": [
        "#Part 4 BERT for arithmetic sentiment analysis\n",
        "\n",
        "Acknowledgement: We used most of the code from https://mccormickml.com/2019/07/22/BERT-fine-tuning/ \n",
        "\n",
        "Most Credit to: \n",
        "Chris McCormick and Nick Ryan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhPwblrwyDxj",
        "colab_type": "text"
      },
      "source": [
        "# Bert Background\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyytew4tyT8z",
        "colab_type": "text"
      },
      "source": [
        "**B**idirectional **E**ncoder **R**epresentations from\n",
        "**T**ransformers (BERT) [Devlin  et  al.,  2019], as the name suggests, is a language model based on the Transformer  [Vaswani et al., 2017] encoder architecture that has been pre-trained on a large dataset of unlabeled sentences from Wikipedia and BookCorpus [Zhu et al., 2015]. Given a sequence of tokens representing sentence(s), BERT outputs a ``contextualized representation\" vector for each of the token. Now, suppose we are given some down-stream tasks, such as sentence classification or question-answering. We can take the BERT model, add a small layer on top of the BERT representation(s), and then fine-tune the added parameters **and** BERT parameters on the down-stream dataset, which is typically much smaller than the data used to pre-train BERT. \n",
        "\n",
        "In traditional language modeling task, the objective is to maximize the log likelihood of predicting the current word (or token) in the sentence, given the previous words (to the left of current work) as context. This is called the *autoregressive model*. In BERT, however, we wish to predict the current word given both the words before and after (i.e. to the left and to the right) of the sentence--hence *bidirectional*.\n",
        "To be able to attend from both directions, BERT uses the encoder Transformer, which does not apply any attention masking unlike the decoder.\n",
        "\n",
        "We briefly describe how BERT is pre-trained. BERT has 2 task objectives for pre-training: (1) *Masked Language Modeling* (Masked LM), and (2) *Next Sentence Prediction*(NSP). The input to the model is a sequence of tokens of the form:\n",
        "```\n",
        "    [CLS] Sentence A [SEP] Sentence B,\n",
        "```\n",
        "where `[CLS]`  (\"class\") and `[SEP]` (\"separator\") are special tokens. \n",
        "In Masked LM, some percentage of the input tokens are converted into `[MASK]` tokens, and the objective is to use the final layer representation for that masked token to predict the correct word that was masked out. For NSP, the task is to use the contextualized representation for the `[CLS]` token to perform binary classification for whether sentence A and sentence B are consecutive sentences in the unlabeled dataset. See Figure 6 (in Handout) for the conceptual picture of BERT pre-training and fine-tuning. \n",
        "\n",
        "In this assignment, you will be **fine-tuning BERT on a single sentence classification task** (see below about the dataset). Figure 7 (in Handout) illustrates the architecture for fine-tuning on this task. We prepend the tokenized sentence with the `[CLS]` token, then feed the sequence into BERT. We then take the contextualized `[CLS]` token representation at the last layer of BERT and add either a softmax layer on top corresponding to the number of output classes in the task. Alternatively, we can have fully connected hidden layers before the softmax layer for more expressivity for harder tasks. Then, both the new layers and the entire BERT parameters are trained end to end on the task for a few epochs. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI",
        "colab_type": "text"
      },
      "source": [
        "## Install transformers repo that has Bert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "2a2ccdee-5279-427a-ab01-258d0325ad82"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 4.8MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 6.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 6.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.18)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 41.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.18)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=a95359cd55fef7c8ad52908ee8baa3154bf5163bfac0150d58a5610ef0b5806a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn",
        "colab_type": "text"
      },
      "source": [
        "## Download & Extract\n",
        "Run the following cells to downlaod the dataset files from the CSC413 webpage.\n",
        "\n",
        "<!-- Download the two csv dataset files from CSC413 webpage, click the folder icon,  -->\n",
        "<!-- and click \"upload\" to upload them.  -->\n",
        "\n",
        "<!-- https://csc413-2020.github.io/assets/misc/PA03_data_20_train.csv \n",
        "\n",
        "https://csc413-2020.github.io/assets/misc/PA03_data_20_test.csv   -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ydihgBb-AiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "df259439-d5a4-4e0a-974b-5090be442db7"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=4123c5e021bfd41247709eaadc8d161c44df4ba90cbec5642c903616b76c1fbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W9K3PG3-C5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3fc0ede0-b821-496b-8bb8-e2dea30ec0ca"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading verbal arithmetic dataset')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://csc413-2020.github.io/assets/misc/'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./PA03_data_20_train.csv'):\n",
        "  wget.download(url + 'PA03_data_20_train.csv', './PA03_data_20_train.csv')\n",
        "  print('Done downloading training data')\n",
        "else:\n",
        "  print('Already downloaded training data')\n",
        "\n",
        "if not os.path.exists('./PA03_data_20_test.csv'):\n",
        "  wget.download(url + 'PA03_data_20_test.csv', './PA03_data_20_test.csv')\n",
        "  print('Done downloading test data')\n",
        "else:\n",
        "  print('Already downloaded test data')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading verbal arithmetic dataset\n",
            "Done downloading training data\n",
            "Done downloading test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##  Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "bef598c3-c987-4dbd-c279-9c5d40c636b9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"./PA03_data_20_train.csv\", header=0, names=[\"index\", \"input\", \"label\"])\n",
        "\n",
        "print(\"Number of data points: \", df.shape[0])\n",
        "sampled = df.sample(10)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points:  640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>596</td>\n",
              "      <td>nine minus sixteen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>51</td>\n",
              "      <td>two plus eleven</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>54</td>\n",
              "      <td>two plus fourteen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>167</td>\n",
              "      <td>eight plus seven</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>96</td>\n",
              "      <td>four plus sixteen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>237</td>\n",
              "      <td>eleven plus seventeen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>114</td>\n",
              "      <td>five plus fourteen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>757</td>\n",
              "      <td>seventeen minus seventeen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>477</td>\n",
              "      <td>three minus seventeen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>618</td>\n",
              "      <td>ten minus eighteen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                      input  label\n",
              "412    596         nine minus sixteen      0\n",
              "114     51            two plus eleven      2\n",
              "41      54          two plus fourteen      2\n",
              "88     167           eight plus seven      2\n",
              "421     96          four plus sixteen      2\n",
              "288    237      eleven plus seventeen      2\n",
              "512    114         five plus fourteen      2\n",
              "533    757  seventeen minus seventeen      1\n",
              "96     477      three minus seventeen      0\n",
              "615    618         ten minus eighteen      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWzpPi92UAH",
        "colab_type": "text"
      },
      "source": [
        "The two properties we actually care about are the the `inputs` and its `label`, which are the questions and the answers.  \n",
        "\n",
        "**label=0** means the result of expression is **negative**\n",
        "\n",
        "**label=1** means the result of expression is **zero**\n",
        "\n",
        "**label=2** means the result of expression is **positive** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5",
        "colab_type": "text"
      },
      "source": [
        "## BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "ff87ebfa21374d2e95eaba862684e79e",
            "9ec75762dc7745a1b2669e458ea806e7",
            "645d42b6fa0a49519325e6164373ac4c",
            "45bd34b264f043b291fdf8d256c62a86",
            "14e6d658b30a4e87ae84e40ddad35850",
            "3b887af5e0c94c379c5fdc936be2686e",
            "bd911470db74449ca6c087f3d4117ca4",
            "a2c035b0c8934108a6df33f59c68d40e"
          ]
        },
        "outputId": "2fa838f7-131b-4705-ce51-25be00f84e8d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff87ebfa21374d2e95eaba862684e79e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1aaca711-009f-4b79-f001-3f2c57940b89"
      },
      "source": [
        "inputs = df.input.values\n",
        "labels = df.label.values\n",
        "print(\"Train data size \", len(inputs))\n",
        "print(' Original: ', inputs[0])\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(inputs[0]))\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inputs[0])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data size  640\n",
            " Original:  five minus twelve\n",
            "Tokenized:  ['five', 'minus', 'twelve']\n",
            "Token IDs:  [2274, 15718, 4376]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNIc4auFUdF",
        "colab_type": "text"
      },
      "source": [
        "We can actually use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKGCCh8izww",
        "colab_type": "text"
      },
      "source": [
        "## BERT Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDcqNlvVhL5W",
        "colab_type": "text"
      },
      "source": [
        "In a deep learning based NLP pipeline, most of the following preprocessing tricks are frequently needed regardless of whether we use BERT or RNN.\n",
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6mceWWOjZnw",
        "colab_type": "text"
      },
      "source": [
        "### Special Tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykk0P9JiKtVe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**`[SEP]`**\n",
        "\n",
        "At the end of every sentence, we need to append the special `[SEP]` token. \n",
        "\n",
        "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86C9objaKu8f",
        "colab_type": "text"
      },
      "source": [
        "**`[CLS]`**\n",
        "\n",
        "For classification tasks, we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
        "\n",
        "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output.\n",
        "\n",
        "On the output of the final transformer, *only the first embedding (corresponding to the [CLS] token) is used by the classifier*.\n",
        "\n",
        ">  \"The first token of every sequence is always a special classification token (`[CLS]`). The final hidden state\n",
        "corresponding to this token is used as the aggregate sequence representation for classification\n",
        "tasks.\" (from the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n",
        "Also, because BERT is trained to only use this [CLS] token for classification, we know that the model has been motivated to encode everything it needs for the classification step into that single 768-value embedding vector.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u51v0kFxeteu",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Length & Attention Mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPNuwqZVK3T6",
        "colab_type": "text"
      },
      "source": [
        "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
        "\n",
        "BERT has two constraints:\n",
        "1. All sentences must be padded or truncated to a single, fixed length.\n",
        "2. The maximum sentence length is 512 tokens.\n",
        "\n",
        "Padding is done with a special `[PAD]` token, which is at index 0 in the BERT vocabulary. \n",
        "\n",
        "The \"Attention Mask\" is simply an array of 1s and 0s indicating which tokens are padding and which aren't \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ",
        "colab_type": "text"
      },
      "source": [
        "## Sentences to IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M296yz577fV",
        "colab_type": "text"
      },
      "source": [
        "The `tokenizer.encode` function combines multiple steps for us:\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "\n",
        "Oddly, this function can perform truncating for us, but doesn't handle padding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJBVKCyl0HZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3102d406-f141-42e8-e210-90ad1c795b79"
      },
      "source": [
        "# For Verbal Arithmetic\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for input in inputs:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_input = tokenizer.encode(\n",
        "                        input,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_input)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', inputs[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  five minus twelve\n",
            "Token IDs: [101, 2274, 15718, 4376, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhwCKszh6ych",
        "colab_type": "text"
      },
      "source": [
        "## Padding & Truncating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0",
        "colab_type": "text"
      },
      "source": [
        "Pad and truncate our sequences so that they all have the same length, `MAX_LEN`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqiWTDrn_nGB",
        "colab_type": "text"
      },
      "source": [
        "First, what's the maximum sentence length in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhUZO9vc_l6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "021cdfb0-a4b5-4cd2-8541-4859d873341b"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp-54FcQ_p3h",
        "colab_type": "text"
      },
      "source": [
        "Given that, let's choose MAX_LEN = 7 since our numerical expression is quite short. Then apply the padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp9BPRd1tMIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "106bc70d-4fda-4699-c921-ad7a936182d2"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "MAX_LEN = 7\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 7 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDs-MYtYH8sL",
        "colab_type": "text"
      },
      "source": [
        "## Attention Masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT",
        "colab_type": "text"
      },
      "source": [
        "The attention mask simply makes it explicit which tokens are actual words versus which are padding. \n",
        "\n",
        "The BERT vocabulary does not use the ID 0, so if a token ID is 0, then it's padding, and otherwise it's a real token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoC24LeEv3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_",
        "colab_type": "text"
      },
      "source": [
        "## Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06",
        "colab_type": "text"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbE-UHvsb7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "13142355-d9a2-45f8-882f-dd78646a37d8"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "print(input_ids)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "set(labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  101  2274 15718 ...   102     0     0]\n",
            " [  101  7093  4606 ...   102     0     0]\n",
            " [  101  2416  4606 ...   102     0     0]\n",
            " ...\n",
            " [  101  2809  4606 ...   102     0     0]\n",
            " [  101  2698 15718 ...   102     0     0]\n",
            " [  101  2176  4606 ...   102     0     0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LzSbTqW9_BR",
        "colab_type": "text"
      },
      "source": [
        "## Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p1uXczp-Je4",
        "colab_type": "text"
      },
      "source": [
        "Our model expects PyTorch tensors rather than numpy.ndarrays, so convert all of our dataset variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5K2A5Ko1RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN",
        "colab_type": "text"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-",
        "colab_type": "text"
      },
      "source": [
        "# 4. Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y_wqqvFhu1dQ"
      },
      "source": [
        "## Question1 [0pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwE1YaCY94Ra",
        "colab_type": "text"
      },
      "source": [
        "The pre-trained neural network here is the normal BERT model from [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). The goal is to add a new classification layer to the pre-trained model. We have provided two example classes to do so.\n",
        "\n",
        "In this part, you need to make your own  `BertCSC413_MLP` class `self.classifier` by, for example, modifying the provided examples: change the number of layers; change the number of hidden neurons; or try a different activation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJKHoftQ_Wsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch.nn as nn\n",
        "class BertCSC413_Linear(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super(BertCSC413_Linear, self).__init__(config)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "\n",
        "class BertCSC413_MLP_Example(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super(BertCSC413_MLP_Example, self).__init__(config)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, config.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "            )\n",
        "\n",
        "class BertCSC413_MLP(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super(BertCSC413_MLP, self).__init__(config)\n",
        "        # Your own classifier goes here\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, config.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "            ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc",
        "colab_type": "text"
      },
      "source": [
        "## Question2 [0pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2C--cnF_TlD",
        "colab_type": "text"
      },
      "source": [
        "We instantiated two different BERT models from `BertCSC413_MLP` class, which are called `model_freeze_bert` and `model_finetune_bert` in the notebook. \n",
        "\n",
        "**Run** the following code to train the models, and attach the training error curves of `model_freeze_bert` and `model_finetune_bert`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "5cdc593b8b8d4cc5b163770a9b5b84ce",
            "ae2c68f5d4124b8894ad0f2ef862986c",
            "d9090201986146768b7cb7d3c3d60700",
            "d10c39f0720543d3ab656eaeed97f9f1",
            "aaa8120662b1443abbca5e02f82d4884",
            "a8a7d4005bef445b8549c282bed0cde3",
            "08668862d5f445238f886fae2f089689",
            "ac52645f834f455086cee795a232c7d8",
            "a58b5eb80e544fb98109faefca75b680",
            "8e587f3863134a9b86c4f57a65b377f9",
            "411a06cd7a2d4f9f8f141cc217dfd394",
            "052e678e5a8a4550b00f7cb67e7c44e0",
            "9952277b59e1417b822075883d4a1d7b",
            "d6b6fa089a814862b594eb4633c65e1b",
            "2909d7d5deea4916b3014c4ed2c09d61",
            "4c29cecbf01b403e8bc60b8a8cd5b3c8"
          ]
        },
        "outputId": "59527649-e602-45dd-a8eb-cf7fd3c37bf6"
      },
      "source": [
        "from transformers import AdamW, BertConfig\n",
        "\n",
        "model_freeze_bert = BertCSC413_MLP.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 3, \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cdc593b8b8d4cc5b163770a9b5b84ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58b5eb80e544fb98109faefca75b680",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCrbP2RUjmXO",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "for name, param in model_freeze_bert.named_parameters():\n",
        "\tif 'classifier' not in name: # classifier layer\n",
        "\t\tparam.requires_grad = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8UyhbERf0W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_finetune_bert = BertCSC413_MLP.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 3,    \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "15e6f6f4-c145-497b-a596-206d19dba51a"
      },
      "source": [
        "# Model parameters visualization\n",
        "params = list(model_finetune_bert.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 203 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.0.weight                                       (768, 768)\n",
            "classifier.0.bias                                             (768,)\n",
            "classifier.2.weight                                         (3, 768)\n",
            "classifier.2.bias                                               (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk",
        "colab_type": "text"
      },
      "source": [
        "We use\n",
        "- Batch size: 32\n",
        "- Learning rate (Adam): 2e-5  \n",
        "- Number of epochs: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBhTDu3jqgeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def train_model(model):      \n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "    epochs = 4\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)\n",
        "    loss_values = []\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "        t0 = time.time()\n",
        "\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            b_input_ids = batch[0] #.to(device)\n",
        "            b_input_mask = batch[1] #.to(device)\n",
        "            b_labels = batch[2] #.to(device)\n",
        "\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # This will return the loss (rather than the model output) because we\n",
        "            # have provided the `labels`.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "            \n",
        "            # The call to `model` always returns a tuple, so we need to pull the \n",
        "            # loss value out of the tuple.\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_train_loss = total_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Store the loss value for plotting the learning curve.\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "            \n",
        "\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "        model.eval()\n",
        "\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            # batch = tuple(t.to(device) for t in batch)\n",
        "            batch = tuple(t for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            \n",
        "            with torch.no_grad():        \n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # This will return the logits rather than the loss because we have\n",
        "                # not provided labels.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask)\n",
        "            \n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            logits = outputs[0]\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            # Calculate the accuracy for this batch of test sentences.\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "            # Accumulate the total accuracy.\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            # Track the number of batches\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "    return loss_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwm_4q5LuHAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "c33fd2c8-eb28-44fb-db34-10d63fc7886b"
      },
      "source": [
        "freeze_bert_loss_vals = train_model(model_freeze_bert) # about 1 minute for 4 epochs using CPU"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.99\n",
            "  Training epcoh took: 0:00:14\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.77\n",
            "  Training epcoh took: 0:00:14\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.71\n",
            "  Training epcoh took: 0:00:14\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:00:14\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX8jzBSluAtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "d1033069-9996-4efe-b034-9d9d8e6f5aee"
      },
      "source": [
        "finttune_bert_loss_vals = train_model(model_finetune_bert) # about 5 minutes for 4 epochs using CPU"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.79\n",
            "  Training epcoh took: 0:01:27\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:01:25\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:01:26\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:01:26\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "e8a06924-8765-4a6e-f2a6-891fad83d3e1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "def plot_loss_vals(loss_vals):\n",
        "    sns.set(style='darkgrid')\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "    plt.plot(loss_vals, 'b-o')\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "plot_loss_vals(freeze_bert_loss_vals)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_7H1trGWQ0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9efc20bd-6951-488e-d07d-7e1833a11024"
      },
      "source": [
        "plot_loss_vals(finttune_bert_loss_vals)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naNxk-y6Bn1F",
        "colab_type": "text"
      },
      "source": [
        "*Run* the evaluation functions.  Report the test performances of using trained model\\_freeze\\_bert and model\\_finetune\\_bert, and briefly discuss why models are failing under certain target labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5bc1b5ad-66d6-45c1-89fe-88543fbce79b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "#df = pd.read_csv(\"./output.txt_test.csv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df = pd.read_csv(\"./PA03_data_20_test.csv\", header=0, names=[\"index\", \"input\", \"label\"])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "inputs = df.input.values\n",
        "labels = df.label.values\n",
        "\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "input_sent = []\n",
        "\n",
        "# For every sentence...\n",
        "for arithmetic_input in inputs:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        arithmetic_input, \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    input_sent.append(arithmetic_input)\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_testdata(model_test, show_all_predictions=False):\n",
        "    print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model_test.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels, input_sents = [], [], []\n",
        "\n",
        "    # Predict \n",
        "    for batch in prediction_dataloader:\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        decoded_inputs = [tokenizer.decode(b_input_ids[i]).strip(\"[CLS] \").strip( \"[SEP] \").strip(\" [PAD] \").strip(\"[PAD]\").strip(\" [SE\") for i in range(len(b_input_ids))]\n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            outputs = model_test(b_input_ids, token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        input_sents.extend(decoded_inputs)\n",
        "        \n",
        "        # Store predictions and true labels\n",
        "        predictions.extend(np.argmax(logits, axis=1))\n",
        "        true_labels.extend(label_ids)\n",
        "    correct = [0,0,0]\n",
        "    totals = [0, 0, 0]\n",
        "    for true_label, prediction in zip(true_labels, predictions):\n",
        "        if true_label == prediction:\n",
        "            correct[true_label] += 1\n",
        "        totals[true_label] += 1\n",
        "    print(\"Number of expressions with negative result\", true_labels.count(0), \"\\n\",  correct[0],  \" predicted correctly\",  \", accuracy \", correct[0]/totals[0] , \"\\n\")\n",
        "    print(\"Number of expressions with 0 result\", true_labels.count(1), \"\\n\",  correct[1], \" predicted correctly\", \", accuracy \", correct[1]/totals[1], \"\\n\")\n",
        "    print(\"Number of expressions with positive result\", true_labels.count(2),\"\\n\",  correct[2], \" predicted correctly\",\", accuracy \", correct[2]/totals[2], \"\\n\")\n",
        "    if show_all_predictions:\n",
        "        index_to_sentiment_map = {0:\"negative\", 1:\"zero\", 2:\"positive\"}\n",
        "        for sent in [sent + \"--> \"+index_to_sentiment_map[index]  for sent, index in zip(input_sents, predictions)]:\n",
        "            print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPr4f5hvzAwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d1e6ae22-c6a7-4695-daac-351d0eed6aa1"
      },
      "source": [
        "eval_testdata(model_freeze_bert, show_all_predictions=False)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 160 test sentences...\n",
            "Number of expressions with negative result 47 \n",
            " 0  predicted correctly , accuracy  0.0 \n",
            "\n",
            "Number of expressions with 0 result 2 \n",
            " 0  predicted correctly , accuracy  0.0 \n",
            "\n",
            "Number of expressions with positive result 111 \n",
            " 111  predicted correctly , accuracy  1.0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH-oKTjNrYB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "26062aca-e7eb-4be9-cd94-1301b225b1ee"
      },
      "source": [
        "eval_testdata(model_finetune_bert, show_all_predictions=False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 160 test sentences...\n",
            "Number of expressions with negative result 47 \n",
            " 47  predicted correctly , accuracy  1.0 \n",
            "\n",
            "Number of expressions with 0 result 2 \n",
            " 0  predicted correctly , accuracy  0.0 \n",
            "\n",
            "Number of expressions with positive result 111 \n",
            " 110  predicted correctly , accuracy  0.990990990990991 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik",
        "colab_type": "text"
      },
      "source": [
        "## Question3 [1pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tezCqLQsB1BJ",
        "colab_type": "text"
      },
      "source": [
        "Try a few unseen examples of arithmetic questions using either model\\_freeze\\_bert or model\\_finetune\\_bert model, and find 10 interesting results.  We will give full marks as long as you provide some comments for why you chose some of the examples. The interesting results can, for example, be both successful extrapolation/interpolation results or surprising failure cases.  You can find some examples in our notebook.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJHaMPJk1AG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_sentiment_map = {0:\"negative\", 1:\"zero\", 2:\"positive\"}\n",
        "model = model_finetune_bert\n",
        "def what_is(arithmetic_input):\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        arithmetic_input, \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                )\n",
        "    input_sent = [arithmetic_input]\n",
        "    input_ids = [encoded_sent]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                            dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask) \n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(torch.tensor(input_ids), token_type_ids=None, \n",
        "                            attention_mask=torch.tensor(attention_masks))\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        print(index_to_sentiment_map[np.argmax(logits, axis=1)[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I-sf_VlOFTQ",
        "colab_type": "code",
        "outputId": "be11c3fa-fa02-4625-e1ec-4b490ab06e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"0 minus 0\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-EyrQtKSJ2W",
        "colab_type": "code",
        "outputId": "c0c0001e-03ed-4ee2-a729-2f73585e6f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"zero plus zero\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5bJMb_NU9Aw",
        "colab_type": "code",
        "outputId": "ab8f1c97-1d74-41c0-b002-a4a08cfb0285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"1 plus 2 minus 4\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkDbHDVhsaMp",
        "colab_type": "code",
        "outputId": "0db67144-e398-429f-c452-9f4e6e31f718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"1 minus 2 plus 4\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u5YxpjcseDI",
        "colab_type": "code",
        "outputId": "84128e7d-252c-47bb-c026-f5bc2f4d3bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"thousand minus hundred\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPckLBdOshTJ",
        "colab_type": "code",
        "outputId": "936f1cfc-bc41-4019-dc52-6fce50a7bcf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"2 + 2 + 100 - 102\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "278259a3-4fff-48dd-804e-0ec67a00fe5f",
        "id": "6a04x0nNWbO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"1 minus 14 \")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJttWunQWdA0",
        "colab_type": "code",
        "outputId": "2f3541a1-4971-48ef-fa7c-4d0e45adbe2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"1 minus two\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4a3KcjuWpmE",
        "colab_type": "code",
        "outputId": "036d5f6b-e3b3-4da4-97fb-7fe636d38153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus two\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLoFyJXPWtrV",
        "colab_type": "code",
        "outputId": "45d10661-7442-4db0-95c4-1defceb799fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"three minus two minus eight\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NvEUBJWx6_",
        "colab_type": "code",
        "outputId": "879541ee-1a0b-44dd-db20-ba7d514b850b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"three minus two minus one plus hundred\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKm-u-uwW3Rd",
        "colab_type": "code",
        "outputId": "f8eccb2d-39d3-453f-aca9-b56a51c81a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus one minus one\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5q21x4YXA6k",
        "colab_type": "code",
        "outputId": "9f01a305-6861-4f85-bc11-d86d487ca5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"one minus one minus one plus 5\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pImh34FXJzu",
        "colab_type": "code",
        "outputId": "e36a1518-3af0-4f0f-813a-9043c40733b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus one plus ten minus one\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGbzrdKTXfVK",
        "colab_type": "code",
        "outputId": "5c8d0dba-d5f2-4752-d835-0d3e211a2944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "what_is(\"minus three plus three\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yhkjxrkNCBF4"
      },
      "source": [
        "## Question4 [1pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4_r_DAtCEJM",
        "colab_type": "text"
      },
      "source": [
        "This is an open question, and we will give marks as long as you show an attempt to try one of the following tasks.   \n",
        "1. Try data augmentation tricks to improve the performances for certain target labels that models were failing to predict.  \n",
        "2. Make a t-sne or PCA plot to visualize the embedding vectors of word tokens related to arithmetic expressions. \n",
        "3. Try different hyperparameter tunings. E.g. learning rates, optimizer, architecture of the classifier, training epochs, and batch size.  \n",
        "4. Evaluate the Multi-class Matthews correlation score for our imbalanced test dataset.  \n",
        "5. Run a baseline model using MLP without pre-trained BERT. You can assume the sequence length of all the data is 3 in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjPuLpiDcmHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "c4ab5765-c532-4853-fb82-bd3854528a53"
      },
      "source": [
        "from random import randrange\n",
        "words = {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 10: 'ten'}\n",
        "operations = ['plus', 'minus']\n",
        "new_inputs = []\n",
        "new_labels = np.zeros(100)\n",
        "for i in range(0,100):\n",
        "  a, b = randrange(1,11), randrange(1,11)\n",
        "  first_num = words[a]\n",
        "  second_num = words[b]\n",
        "  operation = operations[randrange(2)]\n",
        "  new_input = first_num + ' '+ operation + ' ' + second_num\n",
        "  if operation == 'plus':\n",
        "    new_label = a + b\n",
        "  else:\n",
        "    new_label = a - b\n",
        "  if new_label > 0:\n",
        "    new_label = 2\n",
        "  if new_label == 0:\n",
        "    new_label = 1\n",
        "  if new_label < 0:\n",
        "    new_label = 0\n",
        "  new_inputs.append(new_input)\n",
        "  new_labels[i] = new_label\n",
        "df2 = pd.DataFrame({'input':new_inputs, 'label':new_labels})"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  sort=sort,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>512.0</td>\n",
              "      <td>five minus twelve</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>261.0</td>\n",
              "      <td>thirteen plus one</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>139.0</td>\n",
              "      <td>six plus nineteen</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>492.0</td>\n",
              "      <td>four minus twelve</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150.0</td>\n",
              "      <td>seven plus ten</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NaN</td>\n",
              "      <td>three plus eight</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NaN</td>\n",
              "      <td>one plus seven</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NaN</td>\n",
              "      <td>five plus six</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NaN</td>\n",
              "      <td>two plus three</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>NaN</td>\n",
              "      <td>nine minus three</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>740 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    index              input  label\n",
              "0   512.0  five minus twelve    0.0\n",
              "1   261.0  thirteen plus one    2.0\n",
              "2   139.0  six plus nineteen    2.0\n",
              "3   492.0  four minus twelve    0.0\n",
              "4   150.0     seven plus ten    2.0\n",
              "..    ...                ...    ...\n",
              "95    NaN   three plus eight    2.0\n",
              "96    NaN     one plus seven    2.0\n",
              "97    NaN      five plus six    2.0\n",
              "98    NaN     two plus three    2.0\n",
              "99    NaN   nine minus three    2.0\n",
              "\n",
              "[740 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}